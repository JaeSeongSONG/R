wordcount <- table(unlist(nouns)) # list -> vector로 변환
wordcount
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- filter(df_word, nchar(word) >= 2)
top_20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top_20
install.packages('wordcloud')
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer) # 색상표 라이브러리
pal <- brewer.pal(8, 'Dark2')
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
k
# 한글 안될때
Sys.setlocale("LC_ALL", "korean")
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
pal <- brewer.pal(9, 'Blues')
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용용)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
str(twitter)
head(twitter)
twitter$tw <- str_replace_all(twitter$tw, '\\w', ' ')
twitter$tw
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
head(twitter)
twitter$tw <- str_replace_all(twitter$tw, '\\w', ' ')
head(twitter$tw)
twitter$tw <- str_replace_all(twitter$tw, '\\w', ' ')
head(twitter$tw)
wordcount <- table(unlist(nouns))
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
head(twitter)
twitter$tw <- str_replace_all(twitter$tw, '\\w', ' ')
head(twitter$tw)
wordcount <- table(unlist(nouns))
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
wordcount <- table(unlist(nouns))
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
head(twitter)
twitter$tw <- str_replace_all(twitter$tw, '\\w', ' ')
head(twitter$tw)
wordcount <- table(unlist(nouns))
wordcount
wordcount1 <- table(unlist(nouns))
wordcount1
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
head(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
head(twitter)
twitter$tw <- str_replace_all(twitter$tw, '\\w', ' ')
head(twitter$tw)
nouns <- extractNoun(twitter$tw)
nouns
wordcount <- table(unlist(nouns))
wordcount
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
head(twitter)
nouns <- extractNoun(twitter$tw)
nouns
wordcount <- table(unlist(nouns))
wordcount
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- filter(df_word, nchar(word) >= 2)
top20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
library(ggplot2)
order <- arrange(top20, freq)$word
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +
geom_text(aes(label = freq), hjust = - 0.3)
order <- arrange(top20, freq)$word
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +
geom_text(aes(label = freq), hjust = - 0.3)
library(ggplot2)
order <- arrange(top20, freq)$word
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3)     # 빈도 표시
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
head(twitter)
nouns <- extractNoun(twitter$tw)
nouns
wordcount <- table(unlist(nouns))
wordcount
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- filter(df_word, nchar(word) >= 2)
top20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
library(ggplot2)
order <- arrange(top20, freq)$word
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3)     # 빈도 표시
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3))    # 빈도 표시
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3)    # 빈도 표시
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3)    # 빈도 표시
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
top20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
library(KoNLP)
text <- "R은 통계 계산과 그래픽을 위한 프로그래밍 언어이자 소프트웨어 환경이자 프리웨어이다.[2] 뉴질랜드 오클랜드 대학의 로버트 젠틀맨(Robert Gentleman)과 로스 이하카(Ross Ihaka)에 의해 시작되어 현재는 R 코어 팀이 개발하고 있다. R는 GPL 하에 배포되는 S 프로그래밍 언어의 구현으로 GNU S라고도 한다. R는 통계 소프트웨어 개발과 자료 분석에 널리 사용되고 있으며, 패키지 개발이 용이해 통계 소프트웨어 개발에 많이 쓰이고 있다."
extractNoun(text)
library(KoNLP)
text <- "R은 통계 계산과 그래픽을 위한 프로그래밍 언어이자 소프트웨어 환경이자 프리웨어이다.[2] 뉴질랜드 오클랜드 대학의 로버트 젠틀맨(Robert Gentleman)과 로스 이하카(Ross Ihaka)에 의해 시작되어 현재는 R 코어 팀이 개발하고 있다. R는 GPL 하에 배포되는 S 프로그래밍 언어의 구현으로 GNU S라고도 한다. R는 통계 소프트웨어 개발과 자료 분석에 널리 사용되고 있으며, 패키지 개발이 용이해 통계 소프트웨어 개발에 많이 쓰이고 있다."
extractNoun(text)
library(dplyr)
library(stringr)
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
# 한글 안될때
Sys.setlocale("LC_ALL", "korean")
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
d
d
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
twitter
nouns <- extractNoun(twitter$tw)
nouns
wordcount <- table(unlist(nouns))
wordcount
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- filter(df_word, nchar(word) >= 2)
top20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
library(ggplot2)
order <- arrange(top20, freq)$word
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3)    # 빈도 표시
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
library(wordcloud)
library(RColorBrewer) # 색상표 라이브러리
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
pal <- brewer.pal(8, 'Dark2')
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
library(KoNLP)
library(dplyr)
library(stringr)
library(wordcloud)
library(RColorBrewer) # 색상표 라이브러리
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
setwd = 'C:/Sources/StudyR/Busan_202202_R'
getwd()
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
str(twitter)
txt <- readLines('./Busan_202202_R/Data-20220207T040151Z-001/Data/hiphop.txt', encoding = "UTF-8")
txt
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
# 한글 안될때
Sys.setlocale("LC_ALL", "korean")
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
nouns <- extractNoun(twitter$tw)
library(KoNLP)
library(dplyr)
setwd = 'C:/Sources/StudyR/Busan_202202_R'
library(stringr)
library(wordcloud)
library(RColorBrewer) # 색상표 라이브러리
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
# 한글 안될때
Sys.setlocale("LC_ALL", "korean")
twitter <- read.csv('./Busan_202202_R/Data-20220207T040151Z-001/Data/twitter.csv',
header = T,
stringsAsFactors = F,
fileEncoding = 'UTF-8')
twitter <- rename(twitter,
no = 번호,
id = 계정이름,
date = 작성일,
tw = 내용)
nouns <- extractNoun(twitter$tw)
wordcount <- table(unlist(nouns))
wordcount
df_word <- as.data.frame(wordcount, stringsAsFactors = F)
df_word
df_word <- rename(df_word,
word = Var1,
freq = Freq)
df_word
df_word <- filter(df_word, nchar(word) >= 2)
top20 <- df_word %>%
arrange(desc(freq)) %>%
head(20)
top20
library(ggplot2)
order <- arrange(top20, freq)$word
ggplot(data = top20, aes(x = word, y = freq)) +
ylim(0, 2500) =
geom_col() +
coord_flip() +
scale_x_discrete(limit = order) +               # 빈도 순서 변수 기준 막대 정렬
geom_text(aes(label = freq), hjust = - 0.3)    # 빈도 표시
pal <- brewer.pal(8, 'Dark2')
set.seed(1234) # 난수 고정
wordcloud(words = df_word$word, # 단어
freq = df_word$freq,  # 빈도
min.freq = 2,         # 최소 단어 빈도
max.word = 200,       # 표현 단어 수
random.order = F,     # 고빈도 단어 중앙 배치
rot.per = .1,         # 회전 단어 비율
scale = c(4, 0.3),    # 단어 크기 범위
colors = pal)         # 색깔 목록
